# Empirical Cluster-based Analysis of Metaheuristics Similarity
This repository contains our paper submission's code, data, and figures.

In this study, we propose a clustering-based method to analyze the similarity of metaheuristics algorithms based on their performance on benchmark problems.

## Table of Contents
1. [Running Experiments](#running-experiments)
2. [Data Processing]()
3. [Dependencies](#dependencies)

## Running Experiments
This section contains the details to repeat the experiments from the beginning.
This experiment collects the Performance Profiles of the four PSO variants, each with six specified parameter settings, on the bbob suite on 2, 3, 5, and 10 dimensions. Check the section above for the data processing.

### Step 1: Docker
Scripts are in a Docker environment. To initialize the docker:
```
docker build -t ipso .
docker run  -dt --cpus="X"  --name cpso ipso
```
where X is the number of desired CPUs

### Step 2: Performance profiling all PSO variants
Run the experiments:
```
docker exec -t -i cpso /bin/bash
nohup python3 experiment.py -e params/exp.json -a params/pso.json -p params/problems.json &
nohup python3 experiment.py -e params/exp.json -a params/pso_cauchy.json -p params/problems.json &
nohup python3 experiment.py -e params/exp.json -a params/pso_normal.json -p params/problems.json &
nohup python3 experiment.py -e params/exp.json -a params/pso_uniform.json -p params/problems.json &
exit
 ```

 ### Step 3: Accessing the data
 To process the data, first copy the data out of the docker container:
```
 docker cp cpso:/home/mhcmp_pso/exdata ./data_processing
```

 ### Step 4: Stopping Docker and Deleting the Container
```
docker stop cpso
docker rm cpso
```

### INFO: Parameter Files
Three parameter file types are inside the folder [params](mhcmp_pso/params/).
1. [params/exp.json](mhcmp_pso/params/exp.json): Experimental parameters containing the seed and the maximum number of functions evaluated to be used.
2. [params/pso.json](mhcmp_pso/params/pso.json): Meta-parameters for the PSO variant, including pool size and velocity modifier. There is one equivalent file for each PSO variant.
3. [params/problems.json](mhcmp_pso/params/problems.json): Benchmark suite. This file specifies the functions, instances, and dimensions for evaluating the PSO variants.

## Data Processing
After collecting the experimental data, we need to 1) organize the directories, 2) run coco processing, and 3) run our data processing pipeline to analyze the data and generate figures and tables for the paper. The experimental data can be downloaded [here](data/results/2309.zip).

### Organizing the data
First, move the exdata directory to ./data/results/<exp_name>/exdata
If you downloaded the data, exp_name is "2309". Skip to the next step.

If you run the experiments from scratch, we must organize the directories before running cocopp. For this run: 
```
python3 0_organize_exdata.py -path ./data/results/<exp_name>/exdata
```

### COCO Processing and Computing Our Metric
Next, we run the coco processing to generate the ECDFs. Then we compute the metric used for clustering. These are done by running:
```
python3 1_coco_processing.py -exp 2309
```
Replace "2309" with the <exp_name> if necessary.

### Figures and Tables
Figures and tables are generated by the jupyter notebook [2_Figures.ipynb](data/2_Figures.ipynb). Change the exp_name if necessary and run all cells. 

## Dependencies
The experiments are set to run on a docker environment, but the data processing requires these libraries:
* cocopp (coco processing tool)
* numpy
* pandas
* sklearn
* scipy
* matplotlib
* plotly


